{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyhessian import hessian #import specific libraries, use pip install pyhessian"
      ],
      "metadata": {
        "id": "iOEgP3_-CDE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from math import ceil, sqrt\n",
        "#standard python imports"
      ],
      "metadata": {
        "id": "Mhykgte6CQ73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In neural network training we can view the loss space of a function in regards to the Sherrington-Kirkpatrick model, which gives a configuration of neurons (of **N** size and of variance **{-1,1}**) where the weights of each neuron configuration can be mapped as W (i,j), W describes the 'coupling weights' (connections between neurons). Viewing the Hamiltonian of this space allows the Hessian to be taken, since this space is in regards to model loss, the most negative space is seen as the most accurate neuron configuration."
      ],
      "metadata": {
        "id": "HnUAJU8cm_XQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GDnHCcT70xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2a029979-ec08-476e-e583-a1c8dc48d3f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef spatial_hessian_descent2(step_size, dimensionality, start_position, hessian_fn, n_steps=None):\\n  \"\"\"\\n  This code uses the most negative eigenvector of the Hessian, since this value is 2v^T ∇^2Hₙ(σq)v is as negative as possible\\n  We do not use the Gradient of the hessian (first order derivative) because \"we should have ∇HN (σq) ≈ 0, so we probably should not choose v\\n  based on the gradient.\" this is asserting using the first derivate of the Hessian will lead us to local minima and not the global minimum.\\n\\n  \"\"\"\\n  #takes in the step size N as a float value\\n  #the dimensionality of the data\\n  #the subset of\\n\\n  if n_steps is None:\\n    #default if no number is given\\n    n_steps = ceil(1 / step_size)\\n\\n  position = start_position.copy()\\n  trajectory = [position.copy()]\\n\\n  for i in range(n_steps):\\n        # Get current Hessian\\n        hess = hessian_fn(position)\\n\\n  for i in range[ceil(1/n)]:\\n    print(\\'67\\')\\n    #top_eigenvalues, top_eigenvector = fn.eigenvalues() # top eigven value and top eigen vector\\n  return trajectory\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#This verision is depriciated because it was written with numpy and then converted\n",
        "\n",
        "'''\n",
        "def spatial_hessian_descent2(step_size, dimensionality, start_position, hessian_fn, n_steps=None):\n",
        "  \"\"\"\n",
        "  This code uses the most negative eigenvector of the Hessian, since this value is 2v^T ∇^2Hₙ(σq)v is as negative as possible\n",
        "  We do not use the Gradient of the hessian (first order derivative) because \"we should have ∇HN (σq) ≈ 0, so we probably should not choose v\n",
        "  based on the gradient.\" this is asserting using the first derivate of the Hessian will lead us to local minima and not the global minimum.\n",
        "\n",
        "  \"\"\"\n",
        "  #takes in the step size N as a float value\n",
        "  #the dimensionality of the data\n",
        "  #the subset of\n",
        "\n",
        "  if n_steps is None:\n",
        "    #default if no number is given\n",
        "    n_steps = ceil(1 / step_size)\n",
        "\n",
        "  position = start_position.copy()\n",
        "  trajectory = [position.copy()]\n",
        "\n",
        "  for i in range(n_steps):\n",
        "        # Get current Hessian\n",
        "        hess = hessian_fn(position)\n",
        "\n",
        "  for i in range[ceil(1/n)]:\n",
        "    print('67')\n",
        "    #top_eigenvalues, top_eigenvector = fn.eigenvalues() # top eigven value and top eigen vector\n",
        "  return trajectory\n",
        "  '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**\n",
        "---\n",
        "Currently this is using NumPy as the basis for matrix multiplication abd calculating the hessians, eigenvalues/vectors, etc.\n",
        "\n",
        "Switching to torch will allow this to run on CUDA and most likely in parallel, which I am still looking into. doing this will increase effeciency exponentially (if not more)"
      ],
      "metadata": {
        "id": "FAlR3VL14Tus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def spatial_hessian_descent(step_size, dimensionality, start_position, hessian_fn, gradient_fn=None, n_steps=None):\n",
        "    \"\"\"\n",
        "    This code uses the most negative eigenvector of the Hessian, since this value is 2v^T ∇^2Hₙ(σq)v is as negative as possible\n",
        "    We do not use the Gradient of the hessian (first order derivative) because \"we should have ∇HN (σq) ≈ 0, so we probably should not choose v\n",
        "    based on the gradient.\" this is asserting using the first derivate of the Hessian will lead us to local minima and not the global minimum.\n",
        "\n",
        "    Args:\n",
        "        step_size: float, the step size (τ in the paper, typically 1/k),\n",
        "        dimensionality: int, N dimension of the space\n",
        "        start_position: array, starting point σ_0\n",
        "        hessian_fn: function that returns the Hessian matrix at a point\n",
        "        gradient_fn: optional, gradient function (used only to pick sign of direction)\n",
        "        n_steps: int, number of steps k (default: ceil(1/step_size))\n",
        "\n",
        "    Returns:\n",
        "        trajectory: list of positions along the path\n",
        "    \"\"\"\n",
        "    if n_steps is None:\n",
        "        n_steps = ceil(1 / step_size)\n",
        "\n",
        "    position = start_position.clone().to(device)\n",
        "    N = dimensionality #dimensionality\n",
        "    trajectory = [position.clone()]\n",
        "\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        # Get current Hessian\n",
        "        #hessian, the second derivative loss function\n",
        "        hess = hessian_fn(position)\n",
        "\n",
        "        #projects Hessian to orthogonal subspace of current position\n",
        "        #this is needed because we can only move orthogonally to the sphere\n",
        "        norm_sq = torch.dot(position, position)\n",
        "\n",
        "        if norm_sq > 1e-12:\n",
        "            M = torch.eye(N, device=device) - torch.outer(position, position) / norm_sq\n",
        "            hess_proj = M @ hess @ M\n",
        "            #projects to tangent space ensures that the only directions to move or orhtogonal\n",
        "        else:\n",
        "            hess_proj = hess\n",
        "\n",
        "        # get eigenvalues and eigenvectors (sorted ascending, so index 0 is most negative)\n",
        "        #hess_proj = torch.from_numpy(hess_proj)\n",
        "        eigenvalues, eigenvectors = torch.linalg.eigh(hess_proj)\n",
        "\n",
        "\n",
        "        #can also be replaced by PyHessian when in NN applications\n",
        "        #top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues() <---\n",
        "        #where       hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=True)\n",
        "\n",
        "        # Find most negative eigenvector orthogonal to position\n",
        "        v = eigenvectors[:, 0].clone()\n",
        "\n",
        "        if norm_sq > 1e-12 and torch.dot(v, J @ position) < 0:\n",
        "            v = -v\n",
        "\n",
        "        position = position + sqrt(N) * step_size * v\n",
        "\n",
        "        target_q = (i + 1) / n_steps\n",
        "        target_radius = sqrt(N * target_q)\n",
        "        position = position / torch.linalg.norm(position) * target_radius\n",
        "        #goes back from tangent space to the sphere\n",
        "        print(position)\n",
        "        trajectory.append(position.clone())\n",
        "        #has to return current position\n",
        "\n",
        "    return trajectory"
      ],
      "metadata": {
        "id": "bOct7Ydmu52R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**\n",
        "---\n",
        "The current architecture for traversing calcuates the eigenvalues of the Hessian each itteration through (which grows the time complexity of the code). In the case where p=2 we need only calculate the hessian once by\n",
        "**H(σ)=−N​1​i<j∑​Jij​σi​σj**​ this can be done outside of our loop and run one calculation vs N"
      ],
      "metadata": {
        "id": "YGSwK32b_Ff9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spatial_hessian_descent_p2(step_size, dimensionality, start_position, hessian_fn, gradient_fn=None, n_steps=None):\n",
        "    \"\"\"\n",
        "    Optimized for p=2 SK model where Hessian is constant.\n",
        "\n",
        "    Uses the most negative eigenvector of the Hessian, since 2v^T ∇²Hₙ(σq)v\n",
        "    should be as negative as possible.\n",
        "\n",
        "    Args:\n",
        "        step_size: float, the step size (τ in the paper, typically 1/k)\n",
        "        dimensionality: int, N dimension of the space\n",
        "        start_position: tensor, starting point σ_0\n",
        "        hessian_fn: function that returns the Hessian matrix at a point\n",
        "        gradient_fn: optional, gradient function (used only to pick sign of direction)\n",
        "        n_steps: int, number of steps k (default: ceil(1/step_size))\n",
        "\n",
        "    Returns:\n",
        "        trajectory: list of positions along the path\n",
        "    \"\"\"\n",
        "    if n_steps is None:\n",
        "        n_steps = ceil(1 / step_size)\n",
        "\n",
        "    position = start_position.clone().to(device)\n",
        "    N = dimensionality\n",
        "    trajectory = [position.clone()]\n",
        "\n",
        "    # Compute Hessian eigendecomposition ONCE (constant for p=2)\n",
        "    hess = hessian_fn(position)\n",
        "    eigenvalues, eigenvectors = torch.linalg.eigh(hess)\n",
        "\n",
        "    for i in range(n_steps):\n",
        "\n",
        "        norm_sq = torch.dot(position, position)\n",
        "\n",
        "        # Find most negative eigenvector orthogonal to position\n",
        "        for j in range(len(eigenvalues)):\n",
        "            v = eigenvectors[:, j].clone()\n",
        "\n",
        "            # Skip if v is parallel to position\n",
        "            if norm_sq > 1e-10 and abs(torch.dot(v, position)) / torch.sqrt(norm_sq) > 0.99:\n",
        "                continue\n",
        "\n",
        "            # Orthogonalize v to position\n",
        "            if norm_sq > 1e-10:\n",
        "                v = v - torch.dot(v, position) * position / norm_sq\n",
        "                v = v / torch.linalg.norm(v)\n",
        "\n",
        "            # Flip sign if gradient points same direction as v\n",
        "            if gradient_fn is not None and torch.dot(v, gradient_fn(position)) > 0:\n",
        "                v = -v\n",
        "\n",
        "            break\n",
        "\n",
        "        position = position + sqrt(N) * step_size * v\n",
        "\n",
        "        target_q = (i + 1) / n_steps\n",
        "        target_radius = sqrt(N * target_q)\n",
        "        position = position / torch.linalg.norm(position) * target_radius\n",
        "\n",
        "        trajectory.append(position.clone())\n",
        "\n",
        "    return trajectory"
      ],
      "metadata": {
        "id": "pGAFVryU_oLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def project_to_sphere(position, N):\n",
        "    return position / torch.linalg.norm(position) * sqrt(N)"
      ],
      "metadata": {
        "id": "8d9TtVKPn0FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def energy(sigma):\n",
        "    return -torch.dot(sigma, J @ sigma) / (2 * N)\n",
        "    #claude recommended this to check the optimization algortithim's effectiveness in traversal"
      ],
      "metadata": {
        "id": "s4NuUoZaHuK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_plot():\n"
      ],
      "metadata": {
        "id": "gUWTmMky6E-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''The paper proves that this greedy strategy achieves energy:\n",
        "```\n",
        "E(q) = -∫₀^q √(ν''(t)) dt\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0nY867ZMyv46",
        "outputId": "eddca6c8-59b2-4f15-9afd-633919e0a047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The paper proves that this greedy strategy achieves energy:\\n```\\nE(q) = -∫₀^q √(ν''(t)) dt\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#last minute, claude looked at a bottleneck in my code for calculating the eigenvalues\n",
        "#using np instead of something with GPU capabilities (torch in this case)"
      ],
      "metadata": {
        "id": "Mxlqg-Tt5nck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SK model style\n",
        "N = 1100\n",
        "torch.manual_seed(40)\n",
        "J = torch.randn(N, N, N, device=device) #p = 2, σ_i & σ_j\n",
        "#^ this value must be updated when looking at gradients above p = 2\n",
        "J = (J + J.T) / sqrt(2*N)\n",
        "J.fill_diagonal_(0)\n",
        "\n",
        "\n",
        "def my_hessian(sigma):\n",
        "    #can be replaced for other styles of models\n",
        "    #derives hessian from the gradient\n",
        "    return -J\n",
        "\n",
        "def my_gradient(sigma):\n",
        "    #can also be replaced I believe\n",
        "    #this is specific to the S-K model, I believe\n",
        "    return -J @ sigma\n",
        "\n",
        "#def hypothetical_hessian: derived from another model type\n",
        "\n",
        "start = torch.zeros(N, device=device)\n",
        "start[0] = 1e-8\n",
        "\n",
        "trajectory = spatial_hessian_descent(\n",
        "    step_size=0.01,\n",
        "    dimensionality=N,\n",
        "    start_position=start,\n",
        "    hessian_fn=my_hessian,\n",
        "    gradient_fn=my_gradient\n",
        ")\n",
        "\n",
        "print(f\"Steps taken: {len(trajectory)}\")\n",
        "print(f\"Final ||σ||²/N: {torch.linalg.norm(trajectory[-1])**2 / N:.4f}\")\n",
        "#resultant walk distance from origin expressed as a number, should be 1.0 to denote a full traversal\n",
        "print(f\"Final energy: {energy(trajectory[-1]):.4f}\")\n",
        "#should fall around the parisi optimal value energy of about - sqrt(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4AFFgCWvEaC",
        "outputId": "c03d73f6-ab98-4698-9743-fc097356cb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0160, -0.0955,  0.0743,  ..., -0.0173,  0.1097, -0.0247],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0225, -0.1460,  0.1281,  ..., -0.0600,  0.1433, -0.0186],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0277, -0.1695,  0.1371,  ..., -0.0427,  0.1860, -0.0370],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0321, -0.1862,  0.1390,  ..., -0.0201,  0.2238, -0.0559],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0358, -0.2174,  0.1741,  ..., -0.0508,  0.2415, -0.0497],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0393, -0.2292,  0.1725,  ..., -0.0279,  0.2732, -0.0670],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0424, -0.2565,  0.2043,  ..., -0.0575,  0.2866, -0.0600],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0453, -0.2653,  0.2006,  ..., -0.0344,  0.3148, -0.0764],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0480, -0.2902,  0.2305,  ..., -0.0634,  0.3255, -0.0689],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0507, -0.2972,  0.2254,  ..., -0.0401,  0.3514, -0.0847],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0531, -0.3204,  0.2539,  ..., -0.0686,  0.3604, -0.0768],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0555, -0.3260,  0.2477,  ..., -0.0452,  0.3846, -0.0922],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0577, -0.3479,  0.2752,  ..., -0.0734,  0.3921, -0.0840],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0600, -0.3525,  0.2683,  ..., -0.0499,  0.4151, -0.0991],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0620, -0.3734,  0.2950,  ..., -0.0779,  0.4215, -0.0907],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0641, -0.3771,  0.2874,  ..., -0.0543,  0.4435, -0.1055],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0660, -0.3972,  0.3135,  ..., -0.0820,  0.4490, -0.0969],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0680, -0.4003,  0.3054,  ..., -0.0583,  0.4701, -0.1116],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0698, -0.4197,  0.3309,  ..., -0.0860,  0.4749, -0.1028],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0717, -0.4221,  0.3224,  ..., -0.0622,  0.4953, -0.1173],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0734, -0.4410,  0.3475,  ..., -0.0897,  0.4995, -0.1084],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0752, -0.4430,  0.3385,  ..., -0.0659,  0.5193, -0.1227],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0768, -0.4614,  0.3632,  ..., -0.0933,  0.5229, -0.1137],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0785, -0.4628,  0.3540,  ..., -0.0694,  0.5422, -0.1279],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0801, -0.4808,  0.3783,  ..., -0.0967,  0.5454, -0.1188],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0817, -0.4819,  0.3688,  ..., -0.0728,  0.5642, -0.1329],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0832, -0.4995,  0.3928,  ..., -0.1000,  0.5669, -0.1237],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0848, -0.5003,  0.3830,  ..., -0.0760,  0.5853, -0.1377],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0863, -0.5175,  0.4068,  ..., -0.1031,  0.5877, -0.1284],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0878, -0.5180,  0.3968,  ..., -0.0791,  0.6058, -0.1423],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0892, -0.5349,  0.4203,  ..., -0.1062,  0.6078, -0.1330],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0907, -0.5351,  0.4101,  ..., -0.0822,  0.6255, -0.1468],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0920, -0.5518,  0.4334,  ..., -0.1092,  0.6272, -0.1374],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0935, -0.5517,  0.4229,  ..., -0.0851,  0.6446, -0.1511],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0948, -0.5681,  0.4461,  ..., -0.1120,  0.6461, -0.1417],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0962, -0.5678,  0.4355,  ..., -0.0879,  0.6632, -0.1553],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0974, -0.5840,  0.4584,  ..., -0.1148,  0.6644, -0.1458],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0988, -0.5835,  0.4476,  ..., -0.0907,  0.6813, -0.1594],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1000, -0.5995,  0.4704,  ..., -0.1175,  0.6822, -0.1499],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1014, -0.5988,  0.4595,  ..., -0.0934,  0.6989, -0.1634],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1026, -0.6146,  0.4821,  ..., -0.1202,  0.6996, -0.1538],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1039, -0.6137,  0.4710,  ..., -0.0960,  0.7160, -0.1673],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1050, -0.6293,  0.4935,  ..., -0.1228,  0.7165, -0.1577],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1063, -0.6282,  0.4823,  ..., -0.0986,  0.7328, -0.1711],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1074, -0.6437,  0.5047,  ..., -0.1253,  0.7331, -0.1614],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1087, -0.6424,  0.4933,  ..., -0.1011,  0.7491, -0.1748],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1098, -0.6577,  0.5156,  ..., -0.1278,  0.7493, -0.1651],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1110, -0.6563,  0.5041,  ..., -0.1035,  0.7652, -0.1784],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1121, -0.6715,  0.5263,  ..., -0.1302,  0.7652, -0.1687],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1133, -0.6700,  0.5147,  ..., -0.1059,  0.7809, -0.1820],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1144, -0.6850,  0.5367,  ..., -0.1326,  0.7807, -0.1722],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1156, -0.6833,  0.5251,  ..., -0.1083,  0.7963, -0.1855],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1166, -0.6982,  0.5470,  ..., -0.1349,  0.7959, -0.1757],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1178, -0.6964,  0.5352,  ..., -0.1106,  0.8114, -0.1889],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1188, -0.7112,  0.5570,  ..., -0.1372,  0.8109, -0.1791],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1199, -0.7093,  0.5452,  ..., -0.1129,  0.8262, -0.1923],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1209, -0.7239,  0.5669,  ..., -0.1394,  0.8256, -0.1824],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1220, -0.7219,  0.5550,  ..., -0.1151,  0.8407, -0.1956],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1230, -0.7364,  0.5766,  ..., -0.1416,  0.8400, -0.1857],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1241, -0.7343,  0.5646,  ..., -0.1173,  0.8550, -0.1988],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1251, -0.7487,  0.5862,  ..., -0.1438,  0.8542, -0.1889],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1262, -0.7465,  0.5741,  ..., -0.1194,  0.8691, -0.2020],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1271, -0.7608,  0.5956,  ..., -0.1459,  0.8682, -0.1921],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1282, -0.7585,  0.5834,  ..., -0.1215,  0.8829, -0.2052],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1291, -0.7727,  0.6048,  ..., -0.1480,  0.8819, -0.1952],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1302, -0.7703,  0.5926,  ..., -0.1236,  0.8966, -0.2082],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1311, -0.7845,  0.6139,  ..., -0.1501,  0.8954, -0.1983],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1322, -0.7820,  0.6017,  ..., -0.1257,  0.9100, -0.2113],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1331, -0.7960,  0.6229,  ..., -0.1521,  0.9087, -0.2013],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1341, -0.7935,  0.6106,  ..., -0.1277,  0.9232, -0.2143],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1350, -0.8074,  0.6318,  ..., -0.1541,  0.9219, -0.2043],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1360, -0.8048,  0.6194,  ..., -0.1297,  0.9363, -0.2172],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1369, -0.8187,  0.6405,  ..., -0.1561,  0.9348, -0.2072],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1379, -0.8159,  0.6280,  ..., -0.1316,  0.9491, -0.2202],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1387, -0.8298,  0.6491,  ..., -0.1580,  0.9476, -0.2101],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1397, -0.8270,  0.6366,  ..., -0.1336,  0.9618, -0.2230],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1406, -0.8407,  0.6576,  ..., -0.1600,  0.9602, -0.2130],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1415, -0.8378,  0.6450,  ..., -0.1355,  0.9743, -0.2259],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1424, -0.8515,  0.6659,  ..., -0.1619,  0.9726, -0.2158],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1433, -0.8485,  0.6533,  ..., -0.1374,  0.9867, -0.2287],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1442, -0.8621,  0.6742,  ..., -0.1637,  0.9849, -0.2186],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1451, -0.8591,  0.6615,  ..., -0.1393,  0.9989, -0.2315],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1459, -0.8727,  0.6824,  ..., -0.1656,  0.9971, -0.2213],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1469, -0.8696,  0.6697,  ..., -0.1411,  1.0110, -0.2342],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1477, -0.8831,  0.6904,  ..., -0.1674,  1.0091, -0.2240],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1486, -0.8799,  0.6777,  ..., -0.1429,  1.0229, -0.2369],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1494, -0.8934,  0.6984,  ..., -0.1692,  1.0209, -0.2267],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1503, -0.8902,  0.6856,  ..., -0.1447,  1.0347, -0.2396],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1511, -0.9035,  0.7063,  ..., -0.1710,  1.0326, -0.2294],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1520, -0.9003,  0.6935,  ..., -0.1465,  1.0463, -0.2422],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1528, -0.9136,  0.7141,  ..., -0.1728,  1.0442, -0.2320],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1537, -0.9103,  0.7012,  ..., -0.1483,  1.0578, -0.2448],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1545, -0.9235,  0.7218,  ..., -0.1745,  1.0557, -0.2346],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1554, -0.9202,  0.7089,  ..., -0.1500,  1.0692, -0.2474],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1561, -0.9333,  0.7294,  ..., -0.1763,  1.0670, -0.2372],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1570, -0.9299,  0.7165,  ..., -0.1517,  1.0805, -0.2500],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1578, -0.9431,  0.7370,  ..., -0.1780,  1.0782, -0.2397],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1586, -0.9396,  0.7240,  ..., -0.1534,  1.0916, -0.2525],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1594, -0.9527,  0.7445,  ..., -0.1797,  1.0893, -0.2422],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.1602, -0.9492,  0.7314,  ..., -0.1551,  1.1027, -0.2550],\n",
            "       device='cuda:0')\n",
            "Steps taken: 101\n",
            "Final ||σ||²/N: 1.0000\n",
            "Final energy: -0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||σ||² = {torch.dot(trajectory[-1], trajectory[-1]):.2f}\")\n",
        "print(f\"N = {N}\")\n",
        "print(f\"σᵀJσ = {torch.dot(trajectory[-1], J @ trajectory[-1]):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7DgQcJ1MKSA",
        "outputId": "a67630c5-33a3-41bc-a5df-d7d7242b351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||σ||² = 1100.00\n",
            "N = 1100\n",
            "σᵀJσ = 2192.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJzwvQ_05m-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}